
# import pickle
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# with open('All_Combine.pickle', 'rb') as handle:
#   All_Combine = pickle.load(handle)
All_Combine = pd.read_pickle('All_Combine.pickle')
Data = All_Combine['600000']


VariableList = ['Quality_RoE', 'Quality_RoC', 'Quality_RoA',
'Quality_AssetTurnover', 'Quality_Gross margin',
'Quality_EBITDA margin', 'Quality_Berry Ratio',
'Quality_Current ratio', 'Quality_Long-term debt / equity',
'Quality_Operating Profit margin',
'PriceMoMRev_TotRet1D', 'PriceMoMRev_TotRet5D',
'PriceMoMRev_TotRet21D', 'PriceMoMRev_TotRet252D',
'PriceMoMRev_TotRet12M-1M', 'PriceMoMRev_TotRet1260D',
'PriceMoMRev_Lottery', 'PriceMoMRev_vol_volume21D',
'PriceMoMRev_Price-to-52 week high', 'Tech_Realized vol, 1Y',
'Tech_Skewness, 1Y', 'Tech_MAcrossover, 15W-36W, 1Y',
'Tech_CAPM_beta, 5Y monthly',
'Tech_CAPM_idosyncratic_vol, 1Y daily', 'Tech_Kurtosis, 1Y',
'Tech_FloatTurnover, 12M', 'Tech_Log capitalization',
'Growth_EPSGrowth', 'Value_EBITDA/EV',
'Value_Sales/EV', 'Value_PE', 'Value_PS', 'Value_PCF', 'Value_PB', 'Quality_ZScore']
Var = Data[VariableList]
Target = Data['target_monthly']
Sign = pd.DataFrame([1]*len(VariableList),index=VariableList)
Sign.ix[['PriceMoMRev_Lottery','PriceMoMRev_vol_volume21D','Tech_Realized vol, 1Y',
      'Tech_Skewness, 1Y', 'Tech_CAPM_beta, 5Y monthly', 'Tech_CAPM_idosyncratic_vol, 1Y daily',
      'Tech_Kurtosis, 1Y', 'Tech_FloatTurnover, 12M', 'Value_PE', 'Value_PS', 'Value_PCF',
      'Value_PB']] = -1

# print Var.corrwith(Target)
Perform = pd.DataFrame(np.random.randn(len(VariableList), 4),index=VariableList,
                       columns=['PnL', 'IC', 'SR', 'Turnover'])

for Iter in VariableList:
  AllVar = pd.DataFrame()
  Target = pd.DataFrame()
  Price = pd.DataFrame()
  for Iter2 in All_Combine.keys():
    AllVar[Iter2] = All_Combine[Iter2][Iter]
    Target[Iter2] = All_Combine[Iter2]['target_monthly']
    Price[Iter2] = All_Combine[Iter2]['Close']
    Target.fillna(0,inplace=True)
  Weight = AllVar.ix[0:21,].copy()
  PnL = AllVar.iloc[0:21,0].copy()
  Ret = PnL.copy()
  IC = AllVar.iloc[0:21,0].copy()
  Capital = AllVar.iloc[0:21,0].copy()
  Capital.ix[0,] = 100
  LevLimit = 1
  PriceMatrix = np.zeros((21,3))
  for rowID in range(0,21):
    Index = np.argsort(AllVar.ix[rowID,Price.ix[rowID,].notnull()])
    N = int(len(Index)*0.3)
    Weight.ix[rowID,] = 0
    Weight.ix[rowID,Index[:N]] = -1
    Weight.ix[rowID,Index[-N:]] = 1
    Weight.ix[rowID,] = Weight.ix[rowID,] * Sign.ix[Iter,0]
    PriceMatrix[rowID,0] = np.mean(Target.ix[rowID,Index[:N]])
    PriceMatrix[rowID,1] = np.mean(Target.ix[rowID,Index[N:-N]])
    PriceMatrix[rowID,2] = np.mean(Target.ix[rowID,Index[-N:]])
    Adj = LevLimit*Capital.ix[rowID]/sum(abs(Price.ix[rowID,].fillna(0))*abs(Weight.ix[rowID,]))
    Weight.ix[rowID,] = Weight.ix[rowID,]*Adj
    PnL.ix[rowID] = sum(Weight.ix[rowID,]*Target.ix[rowID,])
    IC.ix[rowID] = np.sqrt(1)*pd.DataFrame({'A' : AllVar.ix[rowID,].values.flatten(),
      'B' : Target.ix[rowID,].values.flatten()}).corr(method='spearman').ix[0,1]
    Ret.ix[rowID] = PnL.ix[rowID]/Capital.ix[rowID,]
    if rowID < 20:
      Capital.ix[rowID+1] = Capital.ix[rowID] + PnL.ix[rowID]

  #
  # plt.interactive(False)
  # plt.plot(PnL.index, cumPnL, 'ro')
  # plt.title(Iter)
  # plt.show()


  # plt.interactive(False)
  # plt.plot(PriceMatrix.mean(0), 'ro')
  # plt.title(Iter)
  # plt.show()

  Perform.ix[Iter,'PnL'] = Capital.ix[-1]/100-1
  Perform.ix[Iter,'Turnover'] = abs(Weight.diff()).sum().sum()
  Perform.ix[Iter,'IC'] = np.mean(IC)
  Perform.ix[Iter,'SR'] = np.mean(Ret) / np.std(Ret)

print Perform

# Simple Linear Model where factors are norm inv rank values
import scipy.stats as ss
from scipy.stats import norm
RankedVar = {}
NormVar = {}
for Iter in VariableList:
  AllVar = pd.DataFrame()
  for Iter2 in All_Combine.keys():
    AllVar[Iter2] = All_Combine[Iter2][Iter]
  InvVar = AllVar.copy()
  for rowID in range(AllVar.shape[0]):
    AllVar.ix[rowID,] = ss.rankdata(AllVar.ix[rowID,])/46
    InvVar.ix[rowID,] = norm.ppf(AllVar.ix[rowID,])
  RankedVar[Iter] = AllVar
  NormVar[Iter] = AllVar

XXX = {}
from sklearn.ensemble import ExtraTreesClassifier
AllNormVar = pd.DataFrame()
for Iter in VariableList:
  AllNormVar[Iter] = np.asarray(NormVar[Iter].ix[0:21,].as_matrix()).flatten()

Target = pd.DataFrame()
Price = pd.DataFrame()
MCap = pd.DataFrame()
for Iter2 in All_Combine.keys():
  Target[Iter2] = All_Combine[Iter2]['target_monthly']
  Price[Iter2] = All_Combine[Iter2]['Close']
  MCap[Iter2] = All_Combine[Iter2]['MarketCap']
Target.fillna(0,inplace=True)
MCap.fillna(0,inplace=True)

# use LASSO and BIC for Var Selection
from sklearn.linear_model import Lasso, LassoCV, LassoLarsCV, LassoLarsIC
X = AllNormVar
Y = np.asarray(Target.ix[0:21,].as_matrix()).flatten()


model_bic = LassoLarsIC(criterion='bic')
model_bic.fit(X, Y)

model_cv = LassoCV()
model_cv.fit(X, Y)

model1 = Lasso(alpha=model_bic.alpha_)
model1.fit(X, Y)

model = Lasso(alpha=model_cv.alpha_)
model.fit(X, Y)

# clf = ExtraTreesClassifier()
# clf = clf.fit(X, Y)

Var1 = [val for (idx, val) in enumerate(VariableList) if np.abs(model.coef_[idx])>1e-10]
Var2 = [val for (idx, val) in enumerate(VariableList) if np.abs(model1.coef_[idx])>1e-10]
Var3 = [val for (idx, val) in enumerate(Perform.index) if np.abs(Perform.ix[val,'IC'])>0.02]

from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor, GradientBoostingRegressor, ExtraTreesClassifier
from sklearn.grid_search import GridSearchCV, ParameterGrid
from sklearn.metrics import mean_squared_error
from sklearn import cross_validation

# make forecast one month ahead and update model
Pf2 = []
Weight = AllVar.ix[21:,].copy()
Capital = AllVar.iloc[21:,0].copy()
Capital.ix[0,] = 100
PnL = AllVar.iloc[21:,0].copy()
Ret = PnL.copy()
for rowID in range(21,31):
  AllNormVar = pd.DataFrame()
  AllNormVarTest = pd.DataFrame()
  for Iter in VariableList:
    AllNormVar[Iter] = np.asarray(NormVar[Iter].ix[0:rowID,].as_matrix()).flatten()
    AllNormVarTest[Iter] = np.asarray(NormVar[Iter].ix[rowID,].as_matrix()).flatten()
  X = AllNormVar
  Y = np.asarray(Target.ix[0:rowID,].as_matrix()).flatten()
  YTest = np.asarray(Target.ix[rowID,].as_matrix()).flatten()

  model_bic = LassoLarsIC(criterion='bic')
  model_bic.fit(X, Y)
  model1 = Lasso(alpha=model_bic.alpha_)
  model1.fit(X, Y)
  PredY0 = model1.predict(X)
  PredY = model1.predict(AllNormVarTest)

  # ExtraTreeRegressor
  # parameters = list(ParameterGrid({'max_features': ('auto', 'log2'), 'max_depth': [1, 2, 3, 4, 5, 10, 20, 50, None]}))
  # k_fold = cross_validation.KFold(n=len(Y), n_folds=5)
  # BstPara = None
  # BstScore = 1e5
  # for para in parameters:
  #     Score = 0
  #     for train_indices, test_indices in k_fold:
  #         TrX = X.ix[train_indices,]; TrY = Y[train_indices]
  #         TeX = X.ix[test_indices,]; TeY = Y[test_indices]
  #         clf1 = ExtraTreesRegressor(random_state=0, max_depth=para['max_depth'],max_features=para['max_features'])
  #         clf1.fit(TrX,TrY)
  #         PeY = clf1.predict(TeX)
  #         Score += np.sqrt(mean_squared_error(TeY,PeY))
  #     if Score < BstScore:
  #         BstScore = Score
  #         BstPara = para
  # clf = ExtraTreesRegressor(random_state=0, max_depth=BstPara['max_depth'],max_features=BstPara['max_features'])

  # RandomForestRegressor
  parameters = list(ParameterGrid({'max_features': ('auto', 'log2'), 'max_depth': [1, 2, 3, 4, 5, 10, 20, 50, None],
                                   'n_estimators': [25, 50, 100, 200, 500, 700, 1000, 2000, 5000]}))
  k_fold = cross_validation.KFold(n=len(Y), n_folds=5)
  BstPara = None
  BstScore = 1e5
  for para in parameters:
      Score = 0
      for train_indices, test_indices in k_fold:
          TrX = X.ix[train_indices,]; TrY = Y[train_indices]
          TeX = X.ix[test_indices,]; TeY = Y[test_indices]
          clf1 = RandomForestRegressor(random_state=1, max_depth=para['max_depth'], max_features=para['max_features'],
                                       n_estimators=para['n_estimators'])
          clf1.fit(TrX,TrY)
          PeY = clf1.predict(TeX)
          Score += np.sqrt(mean_squared_error(TeY,PeY))
      if Score < BstScore:
          BstScore = Score
          BstPara = para
  clf = RandomForestRegressor(random_state=1, max_depth=BstPara['max_depth'], max_features=BstPara['max_features'],
                              n_estimators=BstPara['n_estimators'])

  # clf = GradientBoostingRegressor(random_state=1)



  clf.fit(X,Y)
  PredY0 = clf.predict(X)
  PredY = clf.predict(AllNormVarTest)



  Index = np.argsort(PredY)
  N = int(len(Index)*0.3)
  # Weight.ix[rowID-21,Index] = [x / 22.0 for x in range(-22,23)]
  Weight.ix[rowID-21,] = PredY
  # no short sell
  clmID = Weight.ix[rowID-21,]<0
  Weight.ix[rowID - 21,clmID] = 0


  #  #### classification of top 1/3 bot 1/3
  # Index = np.argsort(Y)
  # N = int(len(Index) * 0.3)
  # Y1 = np.zeros((len(Y),1))
  # Y1[Index[:N]] = -1
  # Y1[Index[-N:]] = 1
  #
  # clf = ExtraTreesClassifier(random_state=0)
  # clf.fit(X,Y1)
  # PredY0 = clf.predict(X)
  # PredY = clf.predict(AllNormVarTest)
  #
  # Weight.ix[rowID-21,] = PredY
  # # no short sell
  # # clmID = Weight.ix[rowID-21,]<0
  # # Weight.ix[rowID - 21,clmID] = 0


  # Weight.ix[rowID-21,] = 0
  # Weight.ix[rowID-21,Index[:N]] = -1
  # Weight.ix[rowID-21,Index[-N:]] = 1
  Weight.ix[rowID-21,Price.ix[rowID,].isnull()] = 0
  Adj = LevLimit*Capital.ix[rowID-21]/sum(abs(Price.ix[rowID,].fillna(0))*abs(Weight.ix[rowID-21,]))
  Weight.ix[rowID-21,] = Weight.ix[rowID-21,]*Adj
  PnL.ix[rowID-21] = sum(Weight.ix[rowID-21,]*Target.ix[rowID,])
  Ret.ix[rowID-21] = PnL.ix[rowID-21]/Capital.ix[rowID-21,]
  if rowID < 30:
    Capital.ix[rowID-20] = Capital.ix[rowID-21] + PnL.ix[rowID-21]

  Pf2.append([ss.spearmanr(YTest,PredY)[0], ss.spearmanr(Y,PredY0)[0], Ret.ix[rowID-21]])

print np.mean(Pf2,axis=0), np.std(Pf2,axis=0)
